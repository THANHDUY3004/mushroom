"""
HU·∫§N LUY·ªÜN & ƒê√ÅNH GI√Å ƒêA GI·∫¢I THU·∫¨T
B√†i to√°n: D·ª± ƒëo√°n n·∫•m ƒÇN ƒê∆Ø·ª¢C hay C√ì ƒê·ªòC

C√°c gi·∫£i thu·∫≠t s·ª≠ d·ª•ng (k√®m t√™n ti·∫øng Vi·ªát):
1. Decision Tree        ‚Äì C√¢y quy·∫øt ƒë·ªãnh
2. Random Forest        ‚Äì R·ª´ng ng·∫´u nhi√™n
3. Logistic Regression  ‚Äì H·ªìi quy Logistic
4. Gradient Boosting    ‚Äì TƒÉng c∆∞·ªùng d·∫ßn (Boosting)
5. Naive Bayes          ‚Äì X√°c su·∫•t Bayes ƒë∆°n gi·∫£n

M·ª•c ti√™u:
- So s√°nh ƒë·ªô tin c·∫≠y c√°c m√¥ h√¨nh
- ∆Øu ti√™n Recall c·ªßa l·ªõp "N·∫§M ƒê·ªòC"
- Ch·ªçn m√¥ h√¨nh an to√†n nh·∫•t ƒë·ªÉ tri·ªÉn khai
- L∆∞u bundle m√¥ h√¨nh t·ªët nh·∫•t theo format d√πng trong Flask
"""

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    classification_report, confusion_matrix, roc_auc_score
)
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
import joblib

# =========================
# 1. KHAI B√ÅO THU·ªòC T√çNH
# =========================
FEATURES = [
    'cap-diameter',   # ƒê∆∞·ªùng k√≠nh m≈© (cm)
    'cap-shape',      # H√¨nh d·∫°ng m≈©
    'cap-color',      # M√†u s·∫Øc m≈©
    'stem-height',    # Chi·ªÅu cao th√¢n (cm)
    'stem-width',     # ƒê·ªô r·ªông th√¢n (mm)
    'season'          # M√πa v·ª•
]
TARGET = 'class'      # Nh√£n: e (ƒÉn ƒë∆∞·ª£c), p (ƒë·ªôc)
OUTPUT_PKL = 'mushroom_random_forest_model.pkl'  # gi·ªØ t√™n ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi app Flask hi·ªán c√≥

# =========================
# 2. ƒê·ªåC & TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU
# =========================
def load_and_prepare(path='secondary_data.csv'):
    df = pd.read_csv(path, sep=';')

    # B·ªè d√≤ng thi·∫øu ·ªü c√°c c·ªôt c·∫ßn thi·∫øt
    df = df.dropna(subset=FEATURES + [TARGET]).copy()

    # T√°ch X, y
    X = df[FEATURES].copy()
    y_raw = df[TARGET].astype(str).copy()

    # M√£ h√≥a nh√£n m·ª•c ti√™u: e -> 0 (ƒÉn ƒë∆∞·ª£c), p -> 1 (c√≥ ƒë·ªôc)
    target_encoder = LabelEncoder()
    y = target_encoder.fit_transform(y_raw)
    target_mapping = dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))

    # M√£ h√≥a thu·ªôc t√≠nh ƒë·ªãnh danh
    encoders = {}
    categorical_cols = ['cap-shape', 'cap-color', 'season']
    numeric_cols = ['cap-diameter', 'stem-height', 'stem-width']

    for col in categorical_cols:
        le = LabelEncoder()
        # th√™m 'unknown' ƒë·ªÉ d·ª± ph√≤ng input l·∫° khi ch·∫°y web
        unique_vals = list(X[col].astype(str).unique()) + ['unknown']
        le.fit(unique_vals)
        X.loc[:, col] = le.transform(X[col].astype(str))
        encoders[col] = le

    # Chu·∫©n h√≥a c√°c thu·ªôc t√≠nh s·ªë
    scaler = StandardScaler()
    X.loc[:, numeric_cols] = scaler.fit_transform(X[numeric_cols])

    # Chia train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X.values, y, test_size=0.2, random_state=42, stratify=y
    )

    return X_train, X_test, y_train, y_test, encoders, scaler, target_mapping

# =========================
# 3. DANH S√ÅCH GI·∫¢I THU·∫¨T
# =========================
def build_models():
    return {
        "C√¢y quy·∫øt ƒë·ªãnh (Decision Tree ‚Äì Gini)": 
            DecisionTreeClassifier(criterion="gini", max_depth=10, random_state=42),

        "C√¢y quy·∫øt ƒë·ªãnh (Decision Tree ‚Äì Entropy)": 
            DecisionTreeClassifier(criterion="entropy", max_depth=10, random_state=42),

        "R·ª´ng ng·∫´u nhi√™n (Random Forest)": 
            RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),

        "H·ªìi quy Logistic (Logistic Regression)": 
            LogisticRegression(max_iter=2000, solver="liblinear"),

        "TƒÉng c∆∞·ªùng d·∫ßn (Gradient Boosting)": 
            GradientBoostingClassifier(random_state=42),

        "X√°c su·∫•t Bayes (Naive Bayes)": 
            GaussianNB()
    }


# =========================
# 4. ƒê√ÅNH GI√Å M√î H√åNH
# =========================
def evaluate_model(name, model, X_test, y_test):
    y_pred = model.predict(X_test)

    # Accuracy ‚Äì ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ
    acc = accuracy_score(y_test, y_pred)

    # Precision ‚Äì Recall ‚Äì F1 (macro)
    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(
        y_test, y_pred, average="macro"
    )

    # Recall ri√™ng cho l·ªõp N·∫§M ƒê·ªòC (label = 1)
    _, recall_per_class, _, _ = precision_recall_fscore_support(
        y_test, y_pred, labels=[0, 1]
    )
    recall_poisonous = float(recall_per_class[1])

    # ROC-AUC v√† ƒë·ªô tin c·∫≠y trung b√¨nh n·∫øu model h·ªó tr·ª£ x√°c su·∫•t
    if hasattr(model, "predict_proba"):
        prob = model.predict_proba(X_test)
        roc = roc_auc_score(y_test, prob[:, 1])
        mean_conf = float(np.mean(np.max(prob, axis=1)))
    else:
        roc = np.nan
        mean_conf = float(acc)  # fallback: d√πng Accuracy l√†m proxy ƒë·ªô tin c·∫≠y

    return {
        "name": name,
        "accuracy": float(acc),
        "recall_poisonous": float(recall_poisonous),
        "f1_macro": float(f1_macro),
        "roc_auc": float(roc) if not np.isnan(roc) else np.nan,
        "confidence": float(mean_conf),
        "confusion": confusion_matrix(y_test, y_pred),
        "model": model
    }

def print_table(results):
    print("\n=== B·∫¢NG SO S√ÅNH GI·∫¢I THU·∫¨T ===")
    print(f"{'Gi·∫£i thu·∫≠t':35s} | {'Acc':6s} | {'Recall(ƒë·ªôc)':12s} | {'F1':6s} | {'ROC-AUC':8s} | {'MeanConf':8s}")
    print("-" * 95)
    for r in results:
        roc_str = f"{r['roc_auc']:.3f}" if not np.isnan(r['roc_auc']) else "N/A"
        print(f"{r['name']:35s} | {r['accuracy']*100:6.2f} | {r['recall_poisonous']*100:12.2f} | "
              f"{r['f1_macro']*100:6.2f} | {roc_str:8s} | {r['confidence']:8.3f}")
    print("-" * 95)

# =========================
# 5. CH∆Ø∆†NG TR√åNH CH√çNH
# =========================
def main():
    X_train, X_test, y_train, y_test, encoders, scaler, target_mapping = load_and_prepare()
    models = build_models()
    results = []

    for name, model in models.items():
        print(f"\nüîπ Hu·∫•n luy·ªán gi·∫£i thu·∫≠t: {name}")
        model.fit(X_train, y_train)

        report = evaluate_model(name, model, X_test, y_test)
        results.append(report)

        print(f"‚úî Accuracy                        : {report['accuracy']*100:.2f}%")
        print(f"‚úî Recall (l·ªõp n·∫•m ƒë·ªôc)            : {report['recall_poisonous']*100:.2f}%")
        print(f"‚úî F1-score (macro)                : {report['f1_macro']*100:.2f}%")
        print(f"‚úî ROC-AUC                         : {report['roc_auc'] if not np.isnan(report['roc_auc']) else 0:.3f}")
        print(f"‚úî ƒê·ªô tin c·∫≠y TB (Mean confidence) : {report['confidence']:.3f}")
        print("Ma tr·∫≠n nh·∫ßm l·∫´n:\n", report['confusion'])
        print("B√°o c√°o ph√¢n lo·∫°i:\n",
              classification_report(y_test, model.predict(X_test), target_names=["edible(0)", "poisonous(1)"]))

    # In b·∫£ng t·ªïng h·ª£p
    print_table(results)

    # Ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t ‚Äì ∆∞u ti√™n Recall n·∫•m ƒë·ªôc, sau ƒë√≥ F1, ROC-AUC, Accuracy
    best = sorted(
        results,
        key=lambda r: (r['recall_poisonous'], r['f1_macro'], (r['roc_auc'] if not np.isnan(r['roc_auc']) else -1), r['accuracy']),
        reverse=True
    )[0]

    print("\nüèÜ M√î H√åNH T·ªêT NH·∫§T ƒê∆Ø·ª¢C L·ª∞A CH·ªåN:")
    print(f"üëâ {best['name']}")
    print(f"   Recall(ƒë·ªôc): {best['recall_poisonous']*100:.2f}% | F1: {best['f1_macro']*100:.2f}% | "
          f"ROC-AUC: {best['roc_auc'] if not np.isnan(best['roc_auc']) else 0:.3f} | Acc: {best['accuracy']*100:.2f}%")

    # L∆∞u bundle theo format Flask (classifier, scaler, encoders, features, target_mapping)
    model_bundle = {
        "classifier": best['model'],
        "scaler": scaler,
        "encoders": encoders,
        "features": FEATURES,
        "target_mapping": target_mapping
    }
    # joblib.dump(model_bundle, OUTPUT_PKL)
    # print(f"\nüíæ ƒê√£ l∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i: {os.path.join(os.getcwd(), OUTPUT_PKL)}")

if __name__ == "__main__":
    main()
