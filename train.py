import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
import joblib

# ==========================================
# 1. Táº¢I VÃ€ TIá»€N Xá»¬ LÃ Dá»® LIá»†U
# ==========================================
print("ğŸ“¥ Äang táº£i dá»¯ liá»‡u...")
# Äáº£m báº£o file csv náº±m cÃ¹ng thÆ° má»¥c
df = pd.read_csv("secondary_data.csv", sep=';')

# TÃ¡ch nhÃ£n vÃ  Ä‘áº·c trÆ°ng
X = df.drop('class', axis=1)
y = df['class']

# MÃ£ hÃ³a nhÃ£n má»¥c tiÃªu (e=0, p=1)
le_target = LabelEncoder()
y_encoded = le_target.fit_transform(y)
target_mapping = dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))
print(f"ğŸ“˜ Báº£n Ä‘á»“ nhÃ£n má»¥c tiÃªu: {target_mapping}")

# PhÃ¢n loáº¡i cá»™t sá»‘ vÃ  cá»™t chá»¯
cat_cols = X.select_dtypes(include=['object']).columns
num_cols = X.select_dtypes(exclude=['object']).columns

# Xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u ban Ä‘áº§u
X[cat_cols] = X[cat_cols].fillna('unknown')
X[num_cols] = X[num_cols].fillna(X[num_cols].median())

# ==========================================
# 2. MÃƒ HÃ“A Äáº¶C TRÆ¯NG (TRÃNH Lá»–I UNKNOWN)
# ==========================================
print("âš™ï¸ Äang mÃ£ hÃ³a Ä‘áº·c trÆ°ng...")
encoders = {}
for col in cat_cols:
    le = LabelEncoder()
    # QUAN TRá»ŒNG: Ã‰p LabelEncoder há»c chá»¯ 'unknown' ngay tá»« Ä‘áº§u
    unique_values = X[col].astype(str).unique()
    if 'unknown' not in unique_values:
        unique_values = np.append(unique_values, 'unknown')
    
    le.fit(unique_values)
    X[col] = le.transform(X[col].astype(str))
    encoders[col] = le

# ==========================================
# 3. CHIA Dá»® LIá»†U VÃ€ CHUáº¨N HÃ“A
# ==========================================
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==========================================
# 4. HUáº¤N LUYá»†N MÃ” HÃŒNH
# ==========================================
print("ğŸ—ï¸ Äang huáº¥n luyá»‡n Random Forest (Vui lÃ²ng Ä‘á»£i)...")
# Sá»­ dá»¥ng class_weight='balanced' Ä‘á»ƒ trÃ¡nh thiÃªn kiáº¿n náº¥m Äƒn/Ä‘á»™c
model = RandomForestClassifier(
    n_estimators=200, 
    criterion='entropy',
    class_weight='balanced', 
    random_state=42
)
model.fit(X_train_scaled, y_train)

# ==========================================
# 5. LÆ¯U BUNDLE MODEL
# ==========================================
model_bundle = {
    "classifier": model,
    "scaler": scaler,
    "encoders": encoders,
    "features": list(X.columns),
    "target_mapping": target_mapping
}

joblib.dump(model_bundle, "mushroom_final_model.pkl")
print(f"âœ… ÄÃ£ lÆ°u file: mushroom_final_model.pkl")
print(f"ğŸ“Š Äá»™ chÃ­nh xÃ¡c: {model.score(X_test_scaled, y_test):.2%}")

# ==========================================
# 6. IN THÃ”NG Sá» Äá»‚ Báº N NHáº¬P WEB TEST
# ==========================================
def print_test_samples():
    print("\n" + "="*85)
    print("ğŸ” DANH SÃCH MáºªU Äá»‚ TEST WEB (NHáº¬P CHÃNH XÃC CÃC Sá» NÃ€Y)")
    print("-" * 85)
    print(f"{'STT':<4} | {'LOáº I':<10} | {'DIAM':<6} | {'HEIGHT':<6} | {'WIDTH':<6} | {'SHAPE':<5} | {'COLOR':<5} | {'SEASON'}")
    print("-" * 85)
    
    samples_e = df[df['class'] == 'e'].head(5)
    samples_p = df[df['class'] == 'p'].head(5)
    test_set = pd.concat([samples_e, samples_p])
    
    for i, (_, row) in enumerate(test_set.iterrows(), 1):
        loai = "Ä‚N ÄÆ¯á»¢C" if row['class'] == 'e' else "CÃ“ Äá»˜C"
        print(f"{i:<4} | {loai:<10} | {row['cap-diameter']:<6} | {row['stem-height']:<6} | {row['stem-width']:<6} | {row['cap-shape']:<5} | {row['cap-color']:<5} | {row['season']}")
    
    print("="*85)
    print("ğŸ’¡ LÆ°u Ã½: Náº¿u nháº­p Ä‘Ãºng STT 1-5 mÃ  Web váº«n bÃ¡o CÃ“ Äá»˜C, hÃ£y kiá»ƒm tra láº¡i class_map trong app.py")

if __name__ == "__main__":
    print_test_samples()